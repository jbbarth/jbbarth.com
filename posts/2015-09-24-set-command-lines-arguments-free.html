<!DOCTYPE html>
<html>
  <head>
    <title>jbbarth.com - Set command-line arguments free!</title>
    <link href="http://fonts.googleapis.com/css?family=Lobster+Two:700|Open+Sans:400,600,700" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" media="all" href="/stylesheets/reset.css" />
    <link rel="stylesheet" type="text/css" media="all" href="/stylesheets/960.css" />
    <link rel="stylesheet" type="text/css" media="all" href="/stylesheets/app.css" />
    <meta http-equiv="cache-control" content="max-age=10, must-revalidate" />
    <meta charset="utf-8">
    <meta name="generator" content="nanoc 3.2.3">
  </head>
  <body>
    <div id="container" class="container_16">
      <div class="grid_4">
        <div id="sidebar">
  <div class=sitetitle>
    <a href="/">jbbarth.com</a>
  </div>
  <p>
    I'm a sysadmin &amp; developer from Paris, France. I love building tools for
    ops, and I'm an irregular contributor to many open-source projects. More
    <a href="/portfolio.html">here</a>.
  </p>
</div>

      </div>
      <div class="grid_12">
        <div id="content">
          <h1>Set command-line arguments free!</h1>

<p><em>This is a little manifesto for setting command-line arguments free. They are
hostages of rigorist minds for 3 decades, and now it has to stop.</em></p>

<p>When writing command-line tools, there seems to be a cosmic convergence towards
this model:</p>

<pre><code>$ command subcommand(?) -abc -d --long-opt foo bar baz
</code></pre>

<p>This is OK, and it certainly saves some brain power when it comes to
manipulating hundreds of different commands every day. Older tools, such as
<code>find</code>, even look suspicious for not comforming to that model. Better, most
programming languages have tools to handle that easily, more or less.</p>

<h2>What's wrong with that?</h2>

<p>I certainly won't argue that conventions are not a good thing, they mostly are,
and I could elaborate on this another day. By the way if you want to learn some
basics about UNIX conventions and velociraptors, I strongly recommend watching
this <a href="https://www.youtube.com/watch?v=Qucn0QuXFhc">excellent talk</a> that George
Brocklehurst gave at dotRB 2013, he exposes some fundamentals really well, and
it's funny.</p>

<p>But this form of passing arguments is certainly not for all kind of programs,
and at least <em>sometimes</em>, I'd say that a much more free-form of arguments is
liberating. Beyond this philosophical and weak aergument, this form of passing
arguments in day-to-day operations has a number of practical drawbacks, where a
bit more intelligence built inside your tools may boost your productivity:</p>

<ul>
<li><strong>cognitive overhead</strong>: you have to memorize option names and positions of
arguments ; and some languages/tools are stricter than others (for instance,
some tools don't accept flags after positional arguments, like Docker ; some
need an &quot;=&quot; sign between long options and associated values so that it's not
ambiguous ; some arguments can be repeated, others not ; etc.)</li>
<li><strong>composability with other shell features</strong>: you may find yourself in a
situation where you'd like to use a subshell, or shell expansion (<code>a{1,2,3}</code>)
or globbing (<code>files*.txt</code>) ; the natural separator for these operations is a
space character, and it's incredibly cumbersome to always have some sed or
awk or perl or ruby (pick your own poison) everywhere to just accomodate this</li>
<li><strong>a little more intelligence</strong>: I can't count the number of times I heard a
sysadmin complain about <code>scp</code> copying to a file locally because he forgot the
<code>:</code> character the first time ; basically <em>nobody</em> uses <code>scp</code> to copy from
local to local, and the tool should just figure it out when you're actually
trying to say &quot;copy this file to foo.bar.com&quot; (which is obviously a remote
host) ; and for serious scripting (?), it could have a non-human mode ; or
maybe just display a warning if things are suspicious?</li>
<li><strong>a little less intelligence</strong>: on the other hand, people complain also a lot
about <code>rsync</code> and its weird conventions for copying folders inside folders,
or maybe not, or maybe just if there's a <code>/</code> at the end, or maybe just the
first time and the next time it will do something else, etc. Tools that try
to outsmart you or have weird conventions are not OK either.</li>
</ul>

<h2>A tale of 2 beautiful programs</h2>

<p>I experimented with that recently for two programs.</p>

<p>The first is <strong>logtailer</strong>, a multi-hosts &quot;tail -f&quot; available <a href="https://github.com/botify-labs/logtailer">here</a>.
Server names and absolute paths are easy to detect reliably, so the tool
accepts arguments in any order, and in any number, as long as there's at least
one remote server and one file among them. I don't have to remember any weird
option, and I can use expansions or globbing directly (though I need to quote
globs if I want them to be interpreted on the remote server):</p>

<pre><code>$ logtailer host1.foo.com host2.foo.com /var/log/syslog
$ logtailer /var/log/syslog host1.foo.com /var/log/foo.log
$ logtailer host{1,2,3,4}.foo.com /var/log/syslog &quot;/var/log/**/*.log&quot;
</code></pre>

<p>The second example is a private script called <strong>ec2list</strong> that saves me dozens
of clicks a day in the AWS EC2 console. This script lists all our EC2 instances
(== virtual machines) and displays a number fo basic properties like their
public IP, region, and some tag values that follow our own conventions
here at Botify.</p>

<pre><code># (all instances)
$ ec2list
name=i-0d7b56a1 type=m3.medium region=eu-central-1 az=eu-central-1a ip=47.51.157.251 Env=staging Role=web
name=i-7086fec2 type=m3.xlarge region=us-west-2 az=us-west-2a ip=54.246.17.235 Env=production Role=crawler
...
</code></pre>

<p>Parameters can be used to filter things after retrieval (like a <code>grep -F</code> on
values):</p>

<pre><code># (only crawler instances, in production)
$ ec2list production crawler
name=i-7086fec2 type=m3.xlarge region=us-west-2 az=us-west-2a ip=54.246.17.235 Env=production Role=crawler
</code></pre>

<p>Parameters ending with a &quot;=&quot; are treated as &quot;extractors&quot;. If 0 extractor,
displays everything. If 1 extractor, displays only the values for the given
keys (great for further shell integrations!). If 2+ extractors, it retains the
original format, but displays only the requested columns:</p>

<pre><code># (all crawler instances names, in production)
$ ec2list name= production crawler
i-7086fec2
...
$ ec2list name= type= production crawler
name=i-7086fec2 type=m3.xlarge
...
</code></pre>

<p>OK I could have done this with some <code>cut</code>, <code>grep</code>, <code>sed</code>, ... But I'm
discussing UX here: both for writing, and maybe even some day for other people
who will read a script or a documentation that uses this. Also I think I'll
stop here with <code>ec2list</code>, if I need more complex operations (typically some
&quot;AND&quot; or &quot;OR&quot; in filters), better use the standard tooling after a pipe.</p>

<p>Coupling the two makes tailing logs for instance an order of magnitude easier
and more expressive than before:</p>

<pre><code>$ logtailer $(ec2list ip= staging crawler) /var/log/syslog &quot;/var/log/botify/*.log&quot;
</code></pre>

<p>Compared with something like:</p>

<pre><code>$ badlogtailer \
--hosts $(echo $(badec2list --fields ip --filters staging,crawler|sed &quot;s/^ip=//&quot;) |sed &quot;s/ /,/&quot;) \
--files &quot;/var/log/syslog,/var/log/botify/*.log&quot;
</code></pre>

<p><em>(the latest example is exagerated, it could be simpler with some positional arguments, but you get the idea)</em></p>

<h2>Conclusion</h2>

<p>This is not a <em>revolution</em>, and other tools certainly already do that. But it's
something anyway.</p>

<p>Overall like many things in engineering, it's a matter of tradeoffs:
standardizing generic commands used once in a while is a very good thing for the
UNIX/Linux users community as a whole. But little tools you use 20+ times a day
don't have to follow those rules, they have to be flexible and follow your needs
so you maximize both productivity and happiness.</p>

<p>Now go set some command-line arguments free!</p>

        </div>
      </div>
    </div>
    <script type="text/javascript">
      var _gauges = _gauges || [];
      (function() {
        var t   = document.createElement('script');
        t.type  = 'text/javascript';
        t.async = true;
        t.id    = 'gauges-tracker';
        t.setAttribute('data-site-id', '4e3bca6b613f5d70ee000001');
        t.src = '//secure.gaug.es/track.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(t, s);
      })();
    </script>
  </body>
</html>
